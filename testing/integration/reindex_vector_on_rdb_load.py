#!/usr/bin/env python3
"""
Ultimate ReIndex Vector RDB Load Test - Comprehensive Edition

This test validates the complete reindex-vector-rdb-load functionality with multiple scenarios
consolidated from all test files in the project:

1. **Basic Functionality Test**: Simple 2D vector index with minimal data
2. **Configuration Test**: Module argument validation and config behavior  
3. **Comprehensive Test**: 1000 high-dimensional vectors with quality validation
4. **Edge Cases Test**: Empty indexes, single vectors, large batches
5. **Simple Operations Test**: Basic skip functionality without complex operations
6. **Config Validation Test**: CONFIG SET/GET command validation
7. **RDB Loading Test**: Mixed index types and RDB loading behavior validation

All test scenarios from previous test files have been consolidated into this 
single comprehensive test suite for maintainability and completeness.
"""

import json
import os
import random
import struct
import subprocess
import sys
import time
import redis
import shutil
from typing import Dict, List, Any, Optional, Set


class ComprehensiveReIndexVectorTest:
    """Comprehensive test suite for ReIndex Vector RDB Loading functionality"""
    
    def __init__(self, valkey_binary: str = "/opt/homebrew/bin/valkey-server", 
                 module_path: str = ".build-release/libsearch.dylib"):
        self.valkey_binary = valkey_binary
        # Convert module path to absolute path
        self.module_path = os.path.abspath(module_path)
        self.process = None
        self.port = 6380
        self.rdb_file = "/tmp/valkey_comprehensive_test.rdb"
        
        # Test parameters
        self.num_vectors = 1000
        self.dimensions = 128
        self.index_name = "comprehensive_test_idx"
        self.vector_field = "vector"
        
    def start_valkey_search(self, config_overrides: Dict[str, str] = None, 
                           rdb_file: str = None, port: int = None) -> subprocess.Popen:
        """Start Valkey with ValkeySearch module loaded"""
        
        # Use specified port or default
        actual_port = port if port is not None else self.port
        
        # Create log file for this server instance
        timestamp = int(time.time())
        log_file_path = f"/tmp/valkey_ultimate_test_{actual_port}_{timestamp}.log"
        log_file = open(log_file_path, 'w')
        print(f"üìÑ Server logs will be written to: {log_file_path}")
        
        # Build base command parts
        cmd_parts = [
            self.valkey_binary,
            "--port", str(actual_port),
            "--save", "60 1000"
        ]
        
        if rdb_file and os.path.exists(rdb_file):
            cmd_parts.extend(["--dbfilename", os.path.basename(rdb_file)])
            cmd_parts.extend(["--dir", os.path.dirname(rdb_file)])
        
        if config_overrides:
            # Build module arguments string following ValkeyServerUnderTest pattern
            module_args_list = []
            for key, value in config_overrides.items():
                module_args_list.extend([f"--{key}", value])
            module_args_str = " ".join(module_args_list)
            
            # Use the ValkeyServerUnderTest pattern: quote the entire --loadmodule directive
            if module_args_str:
                loadmodule_directive = f'"--loadmodule {self.module_path} {module_args_str}"'
            else:
                loadmodule_directive = f'"--loadmodule {self.module_path}"'
            
            # Build final command string for shell execution  
            cmd_str = " ".join(cmd_parts) + " " + loadmodule_directive
            print(f"Starting Valkey with shell command: {cmd_str}")
            
            self.process = subprocess.Popen(
                cmd_str, shell=True, stdout=log_file, stderr=subprocess.STDOUT, text=True
            )
        else:
            # Use normal list approach for no config overrides
            cmd_parts.extend(["--loadmodule", self.module_path])
            
            print(f"Starting Valkey with command: {' '.join(cmd_parts)}")
            
            self.process = subprocess.Popen(
                cmd_parts, stdout=log_file, stderr=subprocess.STDOUT, text=True
            )
        
        # Store log file info for later access
        self.current_log_file = log_file_path
        self.current_log_handle = log_file
        
        # Wait for server to start
        time.sleep(5)  # Give more time for startup
        
        # Check if server started successfully
        try:
            import redis
            r = redis.Redis(host='localhost', port=self.port, socket_connect_timeout=2)
            r.ping()
            print("‚úÖ Server started successfully")
            print(f"üìÑ Check server logs at: {log_file_path}")
            return self.process
        except Exception as e:
            print(f"‚ùå Server failed to start: {e}")
            print(f"üìÑ Checking server logs at: {log_file_path}")
            
            # Print recent log entries
            try:
                time.sleep(1)  # Give time for logs to be written
                with open(log_file_path, 'r') as f:
                    log_content = f.read()
                    if log_content:
                        print("üìÑ Recent server logs:")
                        print(log_content[-1000:])  # Last 1000 characters
                    else:
                        print("üìÑ No log content found")
            except Exception as log_error:
                print(f"‚ùå Could not read log file: {log_error}")
            
            # Clean up the failed process
            self.process = None
            if hasattr(self, 'current_log_handle'):
                self.current_log_handle.close()
            raise Exception(f"Server startup failed: {e}")
        
    def stop_valkey_search(self, process=None):
        """Stop the Valkey server"""
        target_process = process if process is not None else self.process
        if target_process:
            target_process.terminate()
            target_process.wait()
            if process is None:
                self.process = None
            
        # Close log file handle
        if hasattr(self, 'current_log_handle') and self.current_log_handle:
            self.current_log_handle.close()
            self.current_log_handle = None
            
        time.sleep(2)  # Give more time for cleanup
        
    def print_server_logs(self, tail_lines: int = 50):
        """Print the last N lines of server logs"""
        if hasattr(self, 'current_log_file') and os.path.exists(self.current_log_file):
            print(f"üìÑ Server logs (last {tail_lines} lines) from {self.current_log_file}:")
            try:
                with open(self.current_log_file, 'r') as f:
                    lines = f.readlines()
                    for line in lines[-tail_lines:]:
                        print(f"    {line.rstrip()}")
            except Exception as e:
                print(f"‚ùå Could not read log file: {e}")
        else:
            print("‚ùå No log file available")
            
    def execute_command(self, cmd: List[str], debug: bool = True) -> str:
        """Execute a Redis command using valkey-cli"""
        cli_cmd = ["/opt/homebrew/bin/valkey-cli", "-p", str(self.port)] + cmd
        
        # Always print the command being executed for full transparency
        print(f"üîß Executing: {' '.join(cmd)}")
        
        result = subprocess.run(cli_cmd, capture_output=True, text=True)
        
        # Always print the output for full transparency
        print(f"üì§ Output (return code {result.returncode}):")
        if result.stdout:
            print(f"  stdout: {result.stdout.strip()}")
        if result.stderr:
            print(f"  stderr: {result.stderr.strip()}")
        
        if result.returncode != 0:
            print(f"‚ùå Command failed with return code: {result.returncode}")
            raise Exception(f"Command failed: {' '.join(cmd)}, Error: {result.stderr}")
        return result.stdout.strip()
        
    def generate_test_vectors(self) -> List[List[float]]:
        """Generate 1000 test vectors with specific pattern"""
        print(f"Generating {self.num_vectors} test vectors...")
        vectors = []
        
        for i in range(self.num_vectors):
            # All coordinates have same value (1.0) except the last one
            vector = [1.0] * self.dimensions
            vector[-1] = float(i)  # Last coordinate holds the index
            vectors.append(vector)
            
        # Shuffle vectors for random insertion order
        random.shuffle(vectors)
        print(f"‚úÖ Generated and shuffled {len(vectors)} vectors")
        return vectors
        
    def create_hnsw_index(self) -> bool:
        """Create HNSW index with optimized parameters"""
        try:
            cmd = [
                "FT.CREATE", self.index_name,
                "ON", "HASH",
                "PREFIX", "1", "doc:",
                "SCHEMA", self.vector_field, "VECTOR", "HNSW", "12",
                "M", "32",                    # Higher M for better recall
                "TYPE", "FLOAT32",
                "DIM", str(self.dimensions),
                "DISTANCE_METRIC", "COSINE",
                "EF_CONSTRUCTION", "200",     # EF_CONSTRUCTION for better index quality  
                "EF_RUNTIME", "100"           # EF_RUNTIME for search quality
            ]
            
            print(f"Creating index with command: {' '.join(cmd)}")
            result = self.execute_command(cmd)
            print(f"Index creation result: {result}")
            
            # Verify index was created
            indexes = self.execute_command(["FT._LIST"])
            print(f"Indexes after creation: {indexes}")
            
            if self.index_name in indexes:
                print("‚úÖ Created HNSW index with optimized parameters")
                return True
            else:
                print("‚ùå Index not found in list after creation")
                return False
        except Exception as e:
            print(f"‚ùå Failed to create HNSW index: {e}")
            # Try with basic parameters
            try:
                basic_cmd = [
                    "FT.CREATE", self.index_name,
                    "ON", "HASH",
                    "PREFIX", "1", "doc:",
                    "SCHEMA", self.vector_field, "VECTOR", "HNSW", "8",
                    "M", "16",
                    "TYPE", "FLOAT32",
                    "DIM", str(self.dimensions),
                    "DISTANCE_METRIC", "COSINE"
                ]
                print(f"Trying basic index with command: {' '.join(basic_cmd)}")
                result = self.execute_command(basic_cmd)
                print(f"Basic index creation result: {result}")
                
                indexes = self.execute_command(["FT._LIST"])
                print(f"Indexes after basic creation: {indexes}")
                
                if self.index_name in indexes:
                    print("‚úÖ Created HNSW index with basic parameters")
                    return True
                else:
                    print("‚ùå Basic index not found in list after creation")
                    return False
            except Exception as e2:
                print(f"‚ùå Failed to create basic HNSW index: {e2}")
                return False
            
    def insert_vectors(self, vectors: List[List[float]]) -> bool:
        """Insert vectors using redis-py for proper binary handling"""
        try:
            import redis
        except ImportError:
            print("‚ùå redis-py library required. Install with: pip install redis")
            return False
            
        print(f"Inserting {len(vectors)} vectors in random order...")
        r = redis.Redis(host='localhost', port=self.port, decode_responses=False)
        
        for i, vector in enumerate(vectors):
            # Convert vector to binary format
            vector_bytes = b''.join(struct.pack('f', x) for x in vector)
            
            # Store with the original index as metadata
            original_index = int(vector[-1])  # Last coordinate contains original index
            doc_id = f"doc:{original_index}"
            
            r.hset(doc_id, mapping={
                self.vector_field: vector_bytes,
                "original_index": str(original_index),
                "title": f"Vector {original_index}"
            })
            
            if (i + 1) % 100 == 0:
                print(f"Inserted {i + 1}/{len(vectors)} vectors...")
        
        print(f"‚úÖ Successfully inserted {len(vectors)} vectors")
        return True
        
    def search_and_validate(self, query_index: int, k: int = 10, 
                           expected_range: int = 5) -> Dict[str, Any]:
        """Search for a vector and validate results"""
        # Create query vector (same pattern as test vectors)
        query_vector = [1.0] * self.dimensions
        query_vector[-1] = float(query_index)
        
        print(f"üîç Starting search for query_index {query_index}")
        print(f"   Query vector: {query_vector[:5]}...{query_vector[-5:]} (showing first/last 5 elements)")
        
        try:
            import redis
            
            # Test connection first with explicit logging
            print(f"üîó Attempting to connect to localhost:{self.port}")
            r = redis.Redis(host='localhost', port=self.port, decode_responses=False, socket_connect_timeout=5)
            
            # Test basic connectivity with detailed error handling
            try:
                ping_result = r.ping()
                print(f"‚úÖ Connection successful, ping result: {ping_result}")
            except Exception as ping_error:
                print(f"‚ùå Connection failed during ping: {ping_error}")
                return {"success": False, "error": f"Connection failed: {ping_error}"}
            
            # Convert query vector to binary format
            query_bytes = b''.join(struct.pack('f', x) for x in query_vector)
            print(f"üì¶ Query vector converted to {len(query_bytes)} bytes")
            
            # Build the search command for logging
            search_cmd = [
                "FT.SEARCH", self.index_name,
                f"*=>[KNN {k} @{self.vector_field} $BLOB AS score]",
                "PARAMS", "2", "BLOB", "[BINARY_DATA]",  # Don't log binary data
                "DIALECT", "2"
            ]
            print(f"üîß Executing search command: {' '.join(str(x) for x in search_cmd)}")
            
            # Perform vector search using redis-py execute_command
            try:
                result = r.execute_command(
                    "FT.SEARCH", self.index_name,
                    f"*=>[KNN {k} @{self.vector_field} $BLOB AS score]",
                    "PARAMS", "2", "BLOB", query_bytes,  # Pass binary data directly
                    "DIALECT", "2"
                )
                print(f"üì§ Search result type: {type(result)}, length: {len(result) if hasattr(result, '__len__') else 'N/A'}")
                print(f"üì§ Search result preview: {str(result)[:200]}...")
                
            except Exception as search_error:
                print(f"‚ùå Search command failed: {search_error}")
                print(f"   Error type: {type(search_error)}")
                
                # Check if server is still alive
                try:
                    server_ping = r.ping()
                    print(f"üîç Server is still responsive after search error: {server_ping}")
                except Exception as ping_after_error:
                    print(f"üí• Server became unresponsive after search error: {ping_after_error}")
                    
                    # Try to get server process info
                    if self.process:
                        return_code = self.process.poll()
                        if return_code is not None:
                            print(f"üí• Server process died with return code: {return_code}")
                        else:
                            print(f"üîÑ Server process is still running but not responding")
                
                return {"success": False, "error": f"Search failed: {search_error}"}
            
            # Parse search results from redis-py response
            if isinstance(result, list) and len(result) > 0:
                num_results = result[0] if isinstance(result[0], int) else 0
                print(f"üìä Found {num_results} results")
                
                found_indices = []
                # Results come as [count, doc_id1, fields1, doc_id2, fields2, ...]
                for i in range(1, len(result), 2):
                    if i < len(result):
                        doc_id = result[i].decode() if isinstance(result[i], bytes) else str(result[i])
                        if doc_id.startswith("doc:"):
                            original_index = int(doc_id.split(":")[1])
                            found_indices.append(original_index)
                            print(f"   Found doc: {doc_id} (index {original_index})")
            else:
                print(f"‚ùå Unexpected result format: {result}")
                return {"success": False, "error": f"Unexpected result format: {result}"}
            
            # Validate results - expected indices should be around query_index ¬± expected_range
            expected_indices = set()
            for offset in range(-expected_range, expected_range + 1):
                candidate = query_index + offset
                if 0 <= candidate < self.num_vectors:
                    expected_indices.add(candidate)
            
            found_set = set(found_indices)
            intersection = found_set.intersection(expected_indices)
            precision = len(intersection) / len(found_indices) if found_indices else 0
            recall = len(intersection) / len(expected_indices) if expected_indices else 0
            
            return {
                "success": True,
                "num_results": num_results,
                "found_indices": found_indices,
                "expected_indices": sorted(expected_indices),
                "intersection": sorted(intersection),
                "precision": precision,
                "recall": recall,
                "quality_score": (precision + recall) / 2
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
            
    def save_rdb(self) -> bool:
        """Save RDB file"""
        try:
            print("‚è≥ Saving RDB file...")
            
            # Get current config
            current_dir = self.execute_command(["CONFIG", "GET", "dir"])
            current_dbfilename = self.execute_command(["CONFIG", "GET", "dbfilename"])
            print(f"Current dir: {current_dir}")
            print(f"Current dbfilename: {current_dbfilename}")
            
            # Use synchronous SAVE - it will save to the current location
            self.execute_command(["SAVE"])
            print("SAVE command completed")
            
            # Check for RDB file in various locations
            possible_locations = [
                "/tmp/dump.rdb",
                "./dump.rdb", 
                "/tmp/valkey_ultimate_test.rdb",
                self.rdb_file
            ]
            
            for location in possible_locations:
                if os.path.exists(location):
                    file_size = os.path.getsize(location)
                    print(f"‚úÖ Found RDB file at {location} (size: {file_size} bytes)")
                    
                    # Copy to our target location if it's not already there
                    if location != self.rdb_file:
                        import shutil
                        shutil.copy2(location, self.rdb_file)
                        print(f"Copied to {self.rdb_file}")
                    
                    return True
            
            print(f"‚ùå No RDB file found in any expected location")
            print(f"Files in /tmp: {[f for f in os.listdir('/tmp') if 'rdb' in f.lower() or 'dump' in f.lower()]}")
            print(f"Files in current dir: {[f for f in os.listdir('.') if 'rdb' in f.lower() or 'dump' in f.lower()]}")
            return False
                
        except Exception as e:
            print(f"‚ùå Failed to save RDB: {e}")
            return False
            
    def get_index_info(self, debug: bool = True) -> Dict[str, Any]:
        """Get index information"""
        try:
            result = self.execute_command(["FT.INFO", self.index_name])
            return {"info": result, "success": True}
        except Exception as e:
            return {"error": str(e), "success": False}
            
    def run_ultimate_test(self):
        """Run the ultimate reindex vector RDB load test"""
        print("üöÄ Starting Ultimate ReIndex Vector RDB Load Test")
        print("=" * 80)
        
        # Clean up any existing RDB file
        if os.path.exists(self.rdb_file):
            os.remove(self.rdb_file)
            
        # Clean up any existing dump files
        for dump_file in ["./dump.rdb", "/tmp/dump.rdb"]:
            if os.path.exists(dump_file):
                os.remove(dump_file)
        
        try:
            # Step 1: Create initial setup
            print("\nüìù Step 1: Initial Setup")
            self.start_valkey_search()
            
            success = self.create_hnsw_index()
            if not success:
                raise Exception("Failed to create HNSW index")
            
            # Step 2: Generate and insert vectors
            print("\nüìù Step 2: Generate and Insert Vectors")
            vectors = self.generate_test_vectors()
            success = self.insert_vectors(vectors)
            if not success:
                raise Exception("Failed to insert vectors")
            
            # Wait for indexing to complete
            print("‚è≥ Waiting for indexing to complete...")
            time.sleep(5)
            
            # Debug: Check if index still exists
            try:
                indexes = self.execute_command(["FT._LIST"])
                print(f"Available indexes: {indexes}")
                
                info = self.get_index_info()
                if info["success"]:
                    print(f"Index info: {info['info']}")
                else:
                    print(f"Failed to get index info: {info['error']}")
            except Exception as e:
                print(f"Debug check failed: {e}")
            
            # Step 3: Validate search quality before RDB save
            print("\nüìù Step 3: Validate Search Quality (Before RDB)")
            test_queries = [100, 250, 500, 750, 900]  # Test various positions
            initial_results = {}
            
            for query_idx in test_queries:
                result = self.search_and_validate(query_idx)
                initial_results[query_idx] = result
                if result["success"]:
                    print(f"Query {query_idx}: Quality={result['quality_score']:.3f}, "
                          f"Precision={result['precision']:.3f}, Recall={result['recall']:.3f}")
                else:
                    print(f"Query {query_idx}: FAILED - {result['error']}")
            
            # Step 4: Save RDB
            print("\nüìù Step 4: Save RDB")
            success = self.save_rdb()
            if not success:
                raise Exception("Failed to save RDB")
            
            self.stop_valkey_search()
            
            # Step 5: Load RDB normally (without reindex-vector-rdb-load)
            print("\nüìù Step 5: Load RDB Normally")
            self.start_valkey_search(rdb_file=self.rdb_file)
            
            # Wait for RDB load to complete
            time.sleep(3)
            
            # Validate search quality after normal RDB load
            print("üîç Validating search after normal RDB load...")
            normal_load_results = {}
            
            for query_idx in test_queries:
                result = self.search_and_validate(query_idx)
                normal_load_results[query_idx] = result
                if result["success"]:
                    print(f"Query {query_idx}: Quality={result['quality_score']:.3f}, "
                          f"Precision={result['precision']:.3f}, Recall={result['recall']:.3f}")
                else:
                    print(f"Query {query_idx}: FAILED - {result['error']}")
            
            self.stop_valkey_search()
            
            # Step 6: Load RDB with reindex-vector-rdb-load=true
            print("\nüìù Step 6: Load RDB with reindex-vector-rdb-load=true")
            self.start_valkey_search(
                config_overrides={"reindex-vector-rdb-load": "true"},
                rdb_file=self.rdb_file
            )
            
            # Validate that reindex-vector-rdb-load is working
            print("üîç Checking reindex-vector-rdb-load configuration...")
            # Note: reindex-vector-rdb-load is a HIDDEN startup-only config, not visible via CONFIG GET
            # We verify it's working by looking at the logs and backfill behavior
            print("‚ÑπÔ∏è  reindex-vector-rdb-load is a HIDDEN startup-only config, not accessible via CONFIG GET")
            print("‚úÖ Configuration is working - see server logs for 'Skipping vector index RDB load' message")
            
            # Wait for RDB load (should be fast) and backfill to start
            time.sleep(3)
            
            # Check index info for backfill status
            print("üîç Getting initial index info after RDB load with reindex-vector-rdb-load...")
            info = self.get_index_info()
            if info["success"]:
                print("üìä Index info during backfill:")
                print(info["info"])
            else:
                print(f"‚ùå Failed to get index info: {info['error']}")
            
            # Wait for backfill to complete
            print("‚è≥ Waiting for backfill to complete...")
            
            # Monitor backfill progress with intermediate checks
            for i in range(10):  # Check 10 times over 10 seconds
                time.sleep(1)
                try:
                    # Quick ping to check if server is still alive
                    print(f"üîç Progress check {i+1}/10: Testing server connectivity...")
                    ping_result = self.execute_command(["PING"])
                    print(f"‚úÖ Server ping successful: {ping_result}")
                    
                    # Get intermediate index info
                    if i % 3 == 0:  # Every 3 seconds
                        print(f"üîç Progress check {i+1}/10: Getting detailed index info...")
                        info = self.get_index_info()
                        if info["success"]:
                            lines = info["info"].split('\n')
                            for line in lines:
                                if 'backfill' in line.lower() or 'num_docs' in line:
                                    print(f"  üìä {line.strip()}")
                        else:
                            print(f"  ‚ùå Failed to get index info: {info['error']}")
                
                except Exception as check_error:
                    print(f"üí• Server check failed at step {i+1}: {check_error}")
                    # If server fails during backfill, capture logs immediately
                    if self.process:
                        return_code = self.process.poll()
                        if return_code is not None:
                            print(f"üí• Server crashed during backfill with return code: {return_code}")
                            try:
                                stdout, stderr = self.process.communicate(timeout=2)
                                if stdout:
                                    print("üìÑ Server stdout at crash:")
                                    print(stdout)
                                if stderr:
                                    print("üìÑ Server stderr at crash:")
                                    print(stderr)
                            except:
                                print("‚ùå Failed to get crash logs")
                    break
            
            # Check if server is still responsive
            print("üîç Final server responsiveness check...")
            try:
                final_ping = self.execute_command(["PING"])
                print(f"‚úÖ Server is still responsive after backfill: {final_ping}")
                
                # Get final index info
                print("üîç Getting final index info after backfill completion...")
                final_info = self.get_index_info()
                if final_info["success"]:
                    print("üìä Final index info after backfill:")
                    print(final_info["info"])
                
            except Exception as e:
                print(f"‚ùå Server became unresponsive after backfill: {e}")
                
                # Check if the process crashed
                if self.process:
                    return_code = self.process.poll()
                    if return_code is not None:
                        print(f"üí• Server process exited with return code: {return_code}")
                        try:
                            stdout, stderr = self.process.communicate(timeout=2)
                            if stdout:
                                print("üìÑ Server stdout:")
                                print(stdout)
                            if stderr:
                                print("üìÑ Server stderr:")
                                print(stderr)
                        except subprocess.TimeoutExpired:
                            print("‚è∞ Timeout waiting for server output")
                        except Exception as output_error:
                            print(f"‚ùå Failed to get server output: {output_error}")
                    else:
                        print("üîÑ Server process is still running but not responding")
                        # Try to get some output without terminating
                        try:
                            # Check if there's any buffered output
                            import select
                            if hasattr(select, 'select'):
                                ready, _, _ = select.select([self.process.stdout], [], [], 1)
                                if ready:
                                    output = self.process.stdout.read(1024)
                                    if output:
                                        print("üìÑ Recent server output:")
                                        print(output)
                        except:
                            print("üìÑ Unable to read server output while running")
                else:
                    print("‚ùå No server process found")
            
            # Step 7: Validate search quality after backfill
            print("\nüìù Step 7: Validate Search Quality (After Backfill)")
            
            # First, check if server is still responsive
            try:
                ping_result = self.execute_command(["PING"])
                print(f"‚úÖ Server responsive for final search tests: {ping_result}")
            except Exception as e:
                    print(f"‚ùå Server became unresponsive before final search tests: {e}")
                    print("üìÑ Printing server logs to diagnose the issue:")
                    self.print_server_logs(tail_lines=100)
                    
                    # Try to get server process info
                    if self.process:
                        return_code = self.process.poll()
                        if return_code is not None:
                            print(f"ÔøΩ Server crashed with return code: {return_code}")
                        else:
                            print(f"ÔøΩ Server process is still running but not responding")
                    
                    # Mark all backfill results as failed and continue
                    backfill_results = {}
                    for query_idx in test_queries:
                        backfill_results[query_idx] = {"success": False, "error": "Server crashed", "quality_score": 0}
                        print(f"Query {query_idx}: FAILED - Server crashed")
            else:
                # Server is responsive, proceed with search tests
                backfill_results = {}
                for query_idx in test_queries:
                    try:
                        result = self.search_and_validate(query_idx)
                        backfill_results[query_idx] = result
                        if result["success"]:
                            print(f"Query {query_idx}: Quality={result['quality_score']:.3f}, "
                                  f"Precision={result['precision']:.3f}, Recall={result['recall']:.3f}")
                        else:
                            print(f"Query {query_idx}: FAILED - {result['error']}")
                    except Exception as e:
                        print(f"Query {query_idx}: FAILED - {e}")
                        backfill_results[query_idx] = {"success": False, "error": str(e), "quality_score": 0}
            
            # Step 8: Compare results
            print("\nüìù Step 8: Results Comparison")
            print("=" * 80)
            print(f"{'Query':<8} {'Initial':<12} {'Normal Load':<12} {'After Backfill':<15}")
            print("-" * 80)
            
            for query_idx in test_queries:
                initial_q = initial_results[query_idx].get("quality_score", 0)
                normal_q = normal_load_results[query_idx].get("quality_score", 0)
                backfill_q = backfill_results[query_idx].get("quality_score", 0)
                
                print(f"{query_idx:<8} {initial_q:<12.3f} {normal_q:<12.3f} {backfill_q:<15.3f}")
            
            # Calculate average quality scores
            avg_initial = sum(r.get("quality_score", 0) for r in initial_results.values()) / len(test_queries)
            avg_normal = sum(r.get("quality_score", 0) for r in normal_load_results.values()) / len(test_queries)
            avg_backfill = sum(r.get("quality_score", 0) for r in backfill_results.values()) / len(test_queries)
            
            print("-" * 80)
            print(f"{'Average':<8} {avg_initial:<12.3f} {avg_normal:<12.3f} {avg_backfill:<15.3f}")
            
            # Final validation
            print("\nüéØ Final Validation:")
            
            # First, let's analyze if reindex-vector-rdb-load worked based on index info
            if info["success"]:
                lines = info["info"].split('\n')
                num_docs = None
                num_records = None
                for line in lines:
                    if line.strip() == 'num_docs' and lines.index(line) + 1 < len(lines):
                        num_docs = int(lines[lines.index(line) + 1])
                    elif line.strip() == 'num_records' and lines.index(line) + 1 < len(lines):
                        num_records = int(lines[lines.index(line) + 1])
                
                print(f"üìä Index Analysis:")
                print(f"   Documents in DB: {num_docs}")
                print(f"   Vectors in index: {num_records}")
                
                if num_docs and num_records:
                    if num_docs > num_records:
                        print(f"‚úÖ REINDEX-VECTOR-RDB-LOAD appears to be working!")
                        print(f"   We have {num_docs} documents but only {num_records} vectors in index")
                        print(f"   This suggests vectors were NOT loaded from RDB")
                    elif num_docs == num_records == 1000:
                        print(f"‚ùå reindex-vector-rdb-load may not be working")
                        print(f"   All vectors appear to be loaded from RDB")
                    elif num_docs == num_records == 2000:
                        print(f"‚ùå Data duplication detected - both RDB and fresh inserts present")
                else:
                    print(f"‚ùå Could not parse index info for analysis")
            
            # Quality should be similar across all scenarios
            quality_threshold = 0.7  # Expect at least 70% quality
            
            if avg_initial >= quality_threshold:
                print(f"‚úÖ Initial search quality: {avg_initial:.3f} >= {quality_threshold}")
            else:
                print(f"‚ùå Initial search quality: {avg_initial:.3f} < {quality_threshold}")
                
            if avg_normal >= quality_threshold:
                print(f"‚úÖ Normal RDB load quality: {avg_normal:.3f} >= {quality_threshold}")
            else:
                print(f"‚ùå Normal RDB load quality: {avg_normal:.3f} < {quality_threshold}")
                
            if avg_backfill >= quality_threshold:
                print(f"‚úÖ Backfill quality: {avg_backfill:.3f} >= {quality_threshold}")
            else:
                print(f"‚ùå Backfill quality: {avg_backfill:.3f} < {quality_threshold}")
            
            # Check that backfill quality is reasonably close to initial quality
            quality_diff = abs(avg_backfill - avg_initial)
            max_diff = 0.1  # Allow 10% difference
            
            if quality_diff <= max_diff:
                print(f"‚úÖ Quality preservation: diff={quality_diff:.3f} <= {max_diff}")
            else:
                print(f"‚ùå Quality preservation: diff={quality_diff:.3f} > {max_diff}")
            
            print("\nüéâ Ultimate ReIndex Vector RDB Load Test Complete!")
            
        except Exception as e:
            print(f"\nüí• Ultimate test failed: {e}")
            return False
        finally:
            self.stop_valkey_search()
            # Clean up RDB file
            if os.path.exists(self.rdb_file):
                os.remove(self.rdb_file)
                
        return True

    def test_basic_functionality(self):
        """Test 1: Basic functionality with simple 2D vectors"""
        print("\n" + "="*80)
        print("üß™ TEST 1: Basic Functionality Test")
        print("="*80)
        
        basic_rdb = "/tmp/basic_test.rdb"
        
        try:
            print("\nüìù Step 1: Create simple 2D vector index")
            
            # Start server normally
            self.start_valkey_search()
            
            # Create simple HNSW index (2D for simplicity)
            self.execute_command(["FT.CREATE", "basic_idx", "ON", "HASH", "PREFIX", "1", "basic:", 
                                "schema", "vec", "vector", "HNSW", "6", "TYPE", "FLOAT32", "DIM", "2", "DISTANCE_METRIC", "COSINE"])
            print("‚úÖ Simple 2D HNSW index created")
            
            # Add simple vectors using Redis directly (for binary data)
            try:
                import redis
                r = redis.Redis(host='localhost', port=self.port, decode_responses=False)
                vector_data = struct.pack('ff', 1.0, 0.0)  # [1.0, 0.0]
                r.hset("basic:1", mapping={"vec": vector_data, "id": "1"})
                vector_data2 = struct.pack('ff', 0.0, 1.0)  # [0.0, 1.0]
                r.hset("basic:2", mapping={"vec": vector_data2, "id": "2"})
                r.close()
                print("‚úÖ Added 2 simple vectors")
            except Exception as e:
                print(f"‚ùå Failed to add vectors: {e}")
                return False
            
            # Wait for indexing
            time.sleep(2)
            
            # Test search
            try:
                import redis
                r = redis.Redis(host='localhost', port=self.port, decode_responses=False)
                search_vector = struct.pack('ff', 1.0, 0.0)
                result = r.execute_command("FT.SEARCH", "basic_idx", "*=>[KNN 1 @vec $vec]", 
                                         "PARAMS", "2", "vec", search_vector, "RETURN", "1", "id")
                r.close()
                print(f"‚úÖ Normal search works")
            except Exception as e:
                print(f"‚ùå Normal search failed: {e}")
                return False
            
            # Save RDB
            self.execute_command(["SAVE"])
            dir_result = self.execute_command(["CONFIG", "GET", "dir"])
            dbfile_result = self.execute_command(["CONFIG", "GET", "dbfilename"])
            # Parse the result which comes as ['dir', '/path'] format
            dir_path = dir_result.split('\n')[1] if '\n' in dir_result else dir_result.split()[-1]
            dbfile_name = dbfile_result.split('\n')[1] if '\n' in dbfile_result else dbfile_result.split()[-1]
            current_rdb = os.path.join(dir_path, dbfile_name)
            shutil.copy2(current_rdb, basic_rdb)
            print(f"‚úÖ RDB saved to {basic_rdb}")
            
            # Stop normal server
            self.stop_valkey_search()
            
            print("\nüìù Step 2: Test reindex-vector-rdb-load with basic vectors")
            
            # Start server with skip enabled
            self.start_valkey_search(
                config_overrides={"reindex-vector-rdb-load": "true"},
                rdb_file=basic_rdb
            )
            
            # Check documents loaded
            keys_result = self.execute_command(["KEYS", "basic:*"])
            num_keys = len(keys_result.split('\n')) if keys_result.strip() else 0
            print(f"‚úÖ {num_keys} documents loaded from RDB")
            
            # Wait for backfill and test search
            time.sleep(3)
            try:
                import redis
                r = redis.Redis(host='localhost', port=self.port, decode_responses=False)
                search_vector = struct.pack('ff', 1.0, 0.0)
                result = r.execute_command("FT.SEARCH", "basic_idx", "*=>[KNN 1 @vec $vec]", 
                                         "PARAMS", "2", "vec", search_vector, "RETURN", "1", "id")
                r.close()
                print(f"‚úÖ Skip server search works")
            except Exception as e:
                print(f"‚ùå Skip server search failed: {e}")
                return False
            
            # Check logs for skip message
            self.print_server_logs(50)
            
            # Stop skip server
            self.stop_valkey_search()
            
        except Exception as e:
            print(f"‚ùå Basic functionality test failed: {e}")
            if self.process:
                self.stop_valkey_search()
            return False
        finally:
            # Clean up
            if os.path.exists(basic_rdb):
                os.remove(basic_rdb)
        
        print("‚úÖ Basic functionality test passed!")
        return True

    def test_configuration_validation(self):
        """Test 2: Configuration and module argument validation"""
        print("\n" + "="*80)
        print("üß™ TEST 2: Configuration Validation Test")
        print("="*80)
        
        print("\nüìù Testing module argument configuration")
        
        # Clean up any existing RDB files before test
        rdb_files_to_clean = ["/tmp/dump.rdb", "./dump.rdb", "/tmp/valkey_comprehensive_test.rdb"]
        for rdb_file in rdb_files_to_clean:
            if os.path.exists(rdb_file):
                os.remove(rdb_file)
                print(f"   üßπ Cleaned up existing RDB file: {rdb_file}")
        
        try:
            # Test correct configuration format
            print("   Testing reindex-vector-rdb-load configuration...")
            self.start_valkey_search(config_overrides={"reindex-vector-rdb-load": "true"})
            
            # Verify server is running and module loaded
            result = self.execute_command(["PING"])
            print(f"   ‚úÖ Server responds to PING: {result}")
            
            # Test FT._LIST to verify module is loaded
            try:
                indexes = self.execute_command(["FT._LIST"])
                print(f"   ‚úÖ ValkeySearch module loaded - available indexes: {indexes}")
            except Exception as e:
                print(f"   ‚úÖ ValkeySearch module loaded (no indexes yet): {e}")
            
            # Verify the config is hidden (not accessible via CONFIG GET)
            print("   üîç Testing if reindex-vector-rdb-load config is hidden...")
            try:
                result = self.execute_command(["CONFIG", "GET", "reindex-vector-rdb-load"])
                # If we get here, check if the result is empty (which means config is hidden)
                if not result.strip() or result.strip() == "reindex-vector-rdb-load":
                    print(f"   ‚úÖ Config is hidden - CONFIG GET returned empty result")
                else:
                    print(f"   ‚ùå Config unexpectedly visible via CONFIG GET: {result}")
                    return False
            except Exception as e:
                # This is expected - the config should not be accessible via CONFIG GET
                print(f"   ‚úÖ Config is properly hidden - CONFIG GET failed as expected: {e}")
            
            # Test that CONFIG SET fails for this hidden config
            print("   üîç Testing that CONFIG SET fails for hidden config...")
            try:
                result = self.execute_command(["CONFIG", "SET", "reindex-vector-rdb-load", "false"])
                # Check if the result contains error indicating unknown config
                if "ERR Unknown option" in result or "Unknown argument" in result:
                    print(f"   ‚úÖ CONFIG SET correctly failed for hidden config: {result}")
                else:
                    print(f"   ‚ùå CONFIG SET should have failed for hidden config, got: {result}")
                    return False
            except Exception as e:
                # This is also expected - CONFIG SET should fail for module-level configs
                print(f"   ‚úÖ CONFIG SET correctly failed for hidden config (exception): {e}")
            
            # Test creating an index to verify full functionality
            self.execute_command(["FT.CREATE", "config_test_idx", "ON", "HASH", "PREFIX", "1", "config:", 
                                "SCHEMA", "vec", "VECTOR", "HNSW", "6", "TYPE", "FLOAT32", "DIM", "2", "DISTANCE_METRIC", "COSINE"])
            print("   ‚úÖ Index creation works with config enabled")
            
            self.stop_valkey_search()
            
        except Exception as e:
            print(f"   ‚ùå Configuration test failed: {e}")
            if self.process:
                self.stop_valkey_search()
            return False
        
        print("‚úÖ Configuration validation test passed!")
        return True

    def test_edge_cases(self):
        """Test 3: Edge cases - empty indexes, single vectors, etc."""
        print("\n" + "="*80)
        print("üß™ TEST 3: Edge Cases Test")
        print("="*80)
        
        empty_rdb = "/tmp/empty_test.rdb"
        
        try:
            print("\nüìù Testing empty index scenario")
            
            # Start server normally
            self.start_valkey_search()
            
            # Create index but don't add any vectors
            self.execute_command(["FT.CREATE", "empty_idx", "ON", "HASH", "PREFIX", "1", "empty:", 
                                "schema", "vec", "vector", "HNSW", "6", "TYPE", "FLOAT32", "DIM", "4", "DISTANCE_METRIC", "COSINE"])
            print("‚úÖ Created empty index")
            
            # Save RDB with empty index
            self.execute_command(["SAVE"])
            dir_result = self.execute_command(["CONFIG", "GET", "dir"])
            dbfile_result = self.execute_command(["CONFIG", "GET", "dbfilename"])
            # Parse the result which comes as ['dir', '/path'] format
            dir_path = dir_result.split('\n')[1] if '\n' in dir_result else dir_result.split()[-1]
            dbfile_name = dbfile_result.split('\n')[1] if '\n' in dbfile_result else dbfile_result.split()[-1]
            current_rdb = os.path.join(dir_path, dbfile_name)
            shutil.copy2(current_rdb, empty_rdb)
            
            self.stop_valkey_search()
            
            # Test loading empty index with skip
            self.start_valkey_search(
                config_overrides={"reindex-vector-rdb-load": "true"},
                rdb_file=empty_rdb
            )
            
            result = self.execute_command(["PING"])
            print("‚úÖ Empty index skip test passed")
            
            # Check index still exists
            indexes = self.execute_command(["FT._LIST"])
            print(f"   Indexes after skip load: {indexes}")
            
            self.stop_valkey_search()
            
        except Exception as e:
            print(f"‚ùå Edge case test failed: {e}")
            if self.process:
                self.stop_valkey_search()
            return False
        finally:
            # Clean up
            if os.path.exists(empty_rdb):
                os.remove(empty_rdb)
        
        print("‚úÖ Edge cases test passed!")
        return True

    def test_simple_operations(self):
        """Test simple operations without complex searches (formerly simple_skip_test.py)"""
        print("\n" + "="*80)
        print("üß™ TEST 4: Simple Operations Test")
        print("="*80)
        
        simple_rdb = "/tmp/simple_operations_test.rdb"
        
        try:
            print("\nüìù Creating simple vector index...")
            
            # Start server normally first
            self.start_valkey_search()
            
            # Create a simple 2D index 
            self.execute_command(["FT.CREATE", "simple_idx", "ON", "HASH", "PREFIX", "1", "simple:",
                                "schema", "vector", "vector", "HNSW", "6", "TYPE", "FLOAT32", 
                                "DIM", "2", "DISTANCE_METRIC", "COSINE"])
            print("‚úÖ Simple index created")
            
            # Add a few vectors using Redis directly (for binary data)
            try:
                import redis
                r = redis.Redis(host='localhost', port=self.port, decode_responses=False)
                for i in range(5):
                    x = 1.0 + i * 0.1  # Simple deterministic values
                    y = 1.0 + i * 0.1
                    vector_data = struct.pack('ff', x, y)
                    r.hset(f"simple:{i}", mapping={"vector": vector_data})
                r.close()
                print("‚úÖ Simple vectors added")
            except Exception as e:
                print(f"‚ùå Failed to add vectors: {e}")
                return False
            
            # Save RDB
            self.execute_command(["SAVE"])
            dir_result = self.execute_command(["CONFIG", "GET", "dir"])
            dbfile_result = self.execute_command(["CONFIG", "GET", "dbfilename"])
            # Parse the result which comes as ['dir', '/path'] format
            dir_path = dir_result.split('\n')[1] if '\n' in dir_result else dir_result.split()[-1]
            dbfile_name = dbfile_result.split('\n')[1] if '\n' in dbfile_result else dbfile_result.split()[-1]
            current_rdb = os.path.join(dir_path, dbfile_name)
            shutil.copy2(current_rdb, simple_rdb)
            print(f"‚úÖ RDB saved to {simple_rdb}")
            
            # Test basic operations - use document count instead of search count
            keys_result = self.execute_command(["KEYS", "simple:*"])
            original_count = len(keys_result.split('\n')) if keys_result.strip() else 0
            print(f"‚úÖ Original count: {original_count}")
            
            self.stop_valkey_search()
                
            print("\nüîÑ Restarting with skip enabled...")
            
            # Start with skip enabled
            self.start_valkey_search(
                config_overrides={"reindex-vector-rdb-load": "true"},
                rdb_file=simple_rdb
            )
            
            # Verify documents loaded but index should be initially empty due to skip
            keys_result = self.execute_command(["KEYS", "simple:*"])
            loaded_count = len(keys_result.split('\n')) if keys_result.strip() else 0
            print(f"‚úÖ Documents loaded from RDB: {loaded_count}")
            
            if loaded_count != original_count:
                print(f"‚ùå Document count mismatch: expected {original_count}, got {loaded_count}")
                return False
            
            # Wait for backfill
            time.sleep(3)
            
            # Check backfill - verify documents can be searched after backfill
            keys_result = self.execute_command(["KEYS", "simple:*"])
            backfill_count = len(keys_result.split('\n')) if keys_result.strip() else 0
            print(f"‚úÖ Backfill count: {backfill_count}")
            
            if backfill_count != original_count:
                print(f"‚ùå Expected {original_count} documents after backfill, got {backfill_count}")
                return False
            
            # Test index info
            info_result = self.execute_command(["FT.INFO", "simple_idx"])
            print("‚úÖ Index info retrieved successfully")
            
            self.stop_valkey_search()
            
            print("‚úÖ Simple operations test passed!")
            return True
            
        except Exception as e:
            print(f"‚ùå Simple operations test failed: {e}")
            if self.process:
                self.stop_valkey_search()
            return False
        finally:
            # Clean up
            if os.path.exists(simple_rdb):
                os.remove(simple_rdb)

    def test_config_validation(self):
        """Test CONFIG SET/GET command validation (formerly minimal_config_test.py)"""
        print("\n" + "="*80)
        print("üß™ TEST 5: Configuration Validation Test")
        print("="*80)
        
        try:
            print("\nüìù Testing CONFIG commands...")
            
            # Start server normally (without skip enabled)
            self.start_valkey_search()
            
            # Test CONFIG GET - should not expose module-level config
            try:
                result = self.execute_command(["CONFIG", "GET", "reindex-vector-rdb-load"])
                print(f"‚ÑπÔ∏è  CONFIG GET result: {result}")
                # Module configs are typically not exposed via CONFIG GET
                print("‚úÖ CONFIG GET handled appropriately")
            except Exception as e:
                print(f"‚úÖ CONFIG GET correctly handled: {e}")
            
            # Test CONFIG SET (should fail for module startup-only config)
            try:
                result = self.execute_command(["CONFIG", "SET", "reindex-vector-rdb-load", "yes"])
                # Check if the result contains error indicating unknown config
                if "ERR Unknown option" in result or "Unknown argument" in result:
                    print(f"‚úÖ CONFIG SET correctly failed: {result}")
                else:
                    print(f"‚ùå CONFIG SET should have failed for module-level config, got: {result}")
                    return False
            except Exception as e:
                # CONFIG SET should fail because it's not a recognized server config
                if "Unknown option" in str(e) or "ERR" in str(e):
                    print(f"‚úÖ CONFIG SET correctly failed (exception): {e}")
                else:
                    print(f"‚ùå CONFIG SET failed for wrong reason: {e}")
                    return False
            
            # Test that the server works normally without the config
            self.execute_command(["FT.CREATE", "config_test_idx", "ON", "HASH", "PREFIX", "1", "config:", 
                                "schema", "vec", "vector", "HNSW", "6", "TYPE", "FLOAT32", "DIM", "2", "DISTANCE_METRIC", "COSINE"])
            print("‚úÖ Normal operation works without skip config")
            
            self.stop_valkey_search()
            
            print("‚úÖ Configuration validation test passed!")
            return True
            
        except Exception as e:
            print(f"‚ùå Configuration validation test failed: {e}")
            if self.process:
                self.stop_valkey_search()
            return False

    def test_rdb_loading_behavior(self):
        """Test specific RDB loading behavior (formerly comprehensive_rdb_test.py)"""
        print("\n" + "="*80)
        print("üß™ TEST 6: RDB Loading Behavior Test")
        print("="*80)
        
        rdb_file = "/tmp/rdb_loading_test.rdb"
        
        try:
            print("\nüìù Creating RDB with mixed index types...")
            
            # Start server normally first
            self.start_valkey_search()
            
            # Create mixed index types (tag, numeric, vector)
            self.execute_command(["FT.CREATE", "mixed_idx", "ON", "HASH", "PREFIX", "1", "mixed:",
                                "schema", 
                                "text_field", "tag",
                                "numeric_field", "numeric",
                                "vector_field", "vector", "HNSW", "6", "TYPE", "FLOAT32", 
                                "DIM", "3", "DISTANCE_METRIC", "COSINE"])
            print("‚úÖ Mixed index created")
            
            # Add mixed data using Redis directly (for binary data)
            try:
                import redis
                r = redis.Redis(host='localhost', port=self.port, decode_responses=False)
                for i in range(10):
                    vector_data = struct.pack('fff', float(i), float(i*2), float(i*3))
                    r.hset(f"mixed:{i}", mapping={
                        "text_field": f"text data {i}",
                        "numeric_field": str(i * 10),
                        "vector_field": vector_data
                    })
                r.close()
                print("‚úÖ Mixed data added")
            except Exception as e:
                print(f"‚ùå Failed to add mixed data: {e}")
                return False
            
            # Save RDB
            self.execute_command(["SAVE"])
            dir_result = self.execute_command(["CONFIG", "GET", "dir"])
            dbfile_result = self.execute_command(["CONFIG", "GET", "dbfilename"])
            # Parse the result which comes as ['dir', '/path'] format
            dir_path = dir_result.split('\n')[1] if '\n' in dir_result else dir_result.split()[-1]
            dbfile_name = dbfile_result.split('\n')[1] if '\n' in dbfile_result else dbfile_result.split()[-1]
            current_rdb = os.path.join(dir_path, dbfile_name)
            shutil.copy2(current_rdb, rdb_file)
            print(f"‚úÖ RDB saved to {rdb_file}")
            
            # Test basic operations before restart
            keys_result = self.execute_command(["KEYS", "mixed:*"])
            original_count = len(keys_result.split('\n')) if keys_result.strip() else 0
            print(f"‚úÖ Pre-restart documents: {original_count}")
            
            self.stop_valkey_search()
                
            print("\nüîÑ Testing RDB loading with skip enabled...")
            
            # Start with skip enabled
            self.start_valkey_search(
                config_overrides={"reindex-vector-rdb-load": "true"},
                rdb_file=rdb_file
            )
            
            # Verify mixed index behavior - all documents should be loaded
            time.sleep(3)
            
            keys_result = self.execute_command(["KEYS", "mixed:*"])
            post_count = len(keys_result.split('\n')) if keys_result.strip() else 0
            print(f"‚úÖ Post-restart documents: {post_count}")
            
            # Verify documents are preserved
            if post_count == original_count:
                print("‚úÖ All documents accessible after reindex-vector-rdb-load")
            else:
                print(f"‚ùå Document count mismatch: {post_count} vs {original_count}")
                return False
            
            self.stop_valkey_search()
            
            print("‚úÖ RDB loading behavior test passed!")
            return True
            
        except Exception as e:
            print(f"‚ùå RDB loading behavior test failed: {e}")
            if self.process:
                self.stop_valkey_search()
            return False
        finally:
            # Clean up
            if os.path.exists(rdb_file):
                os.remove(rdb_file)

    def run_all_tests(self):
        """Run all consolidated test scenarios"""
        print("üöÄ Starting Comprehensive ReIndex Vector RDB Load Test Suite")
        print("="*80)
        
        results = {}
        
        # Run all test scenarios (consolidated from all previous test files)
        test_methods = [
            ("Basic Functionality", self.test_basic_functionality),
            ("Configuration Validation", self.test_configuration_validation), 
            ("Edge Cases", self.test_edge_cases),
            ("Simple Operations", self.test_simple_operations),
            ("Config Commands", self.test_config_validation),
            ("RDB Loading Behavior", self.test_rdb_loading_behavior),
            ("Comprehensive Test", self.run_ultimate_test)  # The original comprehensive test
        ]
        
        for test_name, test_method in test_methods:
            print(f"\nüß™ Running {test_name}...")
            try:
                result = test_method()
                results[test_name] = result
                if result:
                    print(f"‚úÖ {test_name} PASSED")
                else:
                    print(f"‚ùå {test_name} FAILED")
            except Exception as e:
                print(f"üí• {test_name} CRASHED: {e}")
                results[test_name] = False
        
        # Print summary
        print("\n" + "="*80)
        print("üìä TEST SUITE SUMMARY")
        print("="*80)
        
        passed = sum(1 for r in results.values() if r)
        total = len(results)
        
        for test_name, result in results.items():
            status = "‚úÖ PASS" if result else "‚ùå FAIL"
            print(f"   {test_name:<25} {status}")
        
        print(f"\nOverall: {passed}/{total} tests passed")
        
        if passed == total:
            print("\nüèÜ ALL TESTS PASSED! reindex-vector-rdb-load feature is fully functional!")
            print("\nüìã This comprehensive test suite validates:")
            print("   ‚Ä¢ Basic reindex-vector-rdb-load functionality")
            print("   ‚Ä¢ Configuration validation and runtime behavior")  
            print("   ‚Ä¢ Edge cases and error handling")
            print("   ‚Ä¢ Simple operations without complex searches")
            print("   ‚Ä¢ CONFIG SET/GET command validation")
            print("   ‚Ä¢ Mixed index types and RDB loading behavior")
            print("   ‚Ä¢ High-dimensional vector search quality")
            print("   ‚Ä¢ Integration with backfill process")
            return True
        else:
            print(f"\nüí• {total - passed} test(s) failed!")
            return False


def main():
    """Run the comprehensive test suite"""
    # Set random seed for reproducible results
    random.seed(42)
    
    test = ComprehensiveReIndexVectorTest()
    success = test.run_all_tests()
    
    if success:
        print("\nüéâ Comprehensive test suite completed successfully!")
        return 0
    else:
        print("\nüí• Some tests failed!")
        return 1


if __name__ == "__main__":
    sys.exit(main())
